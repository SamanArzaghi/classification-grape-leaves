{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tymu1aosw9Pf"
      },
      "source": [
        "# Side code(used pytorch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCpREQI4ej4g"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import copy\n",
        "import random\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models\n",
        "from torchvision import transforms\n",
        "from torch.optim.lr_scheduler import StepLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMWHanWMgnRu"
      },
      "outputs": [],
      "source": [
        "# transforms\n",
        "org_trasnform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "all_data = datasets.ImageFolder(\n",
        "    root='Grapevine_Leaves_Image_Dataset',\n",
        "    transform=org_trasnform)\n",
        "\n",
        "\n",
        "train_set, test_set = torch.utils.data.random_split(all_data, [400, 100])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4timjaP7BhJ"
      },
      "outputs": [],
      "source": [
        "new_one = copy.deepcopy(train_set)\n",
        "new_two = copy.deepcopy(train_set)\n",
        "new_three = copy.deepcopy(train_set)\n",
        "new_four = copy.deepcopy(train_set)\n",
        "new_five = copy.deepcopy(train_set)\n",
        "\n",
        "new_one.dataset.transform = transforms.Compose([\n",
        "                transforms.RandomHorizontalFlip(p=0.8),\n",
        "                transforms.RandomVerticalFlip(p=0.8),\n",
        "                transforms.RandomRotation(random.randint(1, 180)),\n",
        "                transforms.ToTensor()\n",
        "                ])\n",
        "new_two.dataset.transform = transforms.Compose([\n",
        "                transforms.RandomHorizontalFlip(p=0.8),\n",
        "                transforms.RandomVerticalFlip(p=0.8),\n",
        "                transforms.RandomRotation(random.randint(181, 359)),\n",
        "                transforms.ToTensor()\n",
        "                ])\n",
        "\n",
        "# new_three.dataset.transform = transforms.Compose([\n",
        "#                 transforms.RandomHorizontalFlip(p=0.8),\n",
        "#                 transforms.RandomVerticalFlip(p=0.8),\n",
        "#                 transforms.RandomRotation(random.randint(181, 270)),\n",
        "#                 transforms.ToTensor()\n",
        "#                 ])\n",
        "# new_four.dataset.transform = transforms.Compose([\n",
        "#                 transforms.RandomHorizontalFlip(p=0.8),\n",
        "#                 transforms.RandomVerticalFlip(p=0.8),\n",
        "#                 transforms.RandomRotation(random.randint(271, 359)),\n",
        "#                 transforms.ToTensor()\n",
        "#                 ])\n",
        "\n",
        "train_set = torch.utils.data.ConcatDataset([train_set,new_one])\n",
        "train_set = torch.utils.data.ConcatDataset([train_set,new_two])\n",
        "# train_set = torch.utils.data.ConcatDataset([train_set,new_three])\n",
        "# train_set = torch.utils.data.ConcatDataset([train_set,new_four])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ9yWJdBgrjH"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=10,\n",
        "    shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=10,\n",
        "    shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XltZau3gtNV"
      },
      "outputs": [],
      "source": [
        "model = models.mobilenet_v2(pretrained=True)\n",
        "# num_ftrs = model.classifier[3].in_features\n",
        "# model.classifier[3] = nn.Linear(num_ftrs, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jqEUAjRgu3m"
      },
      "outputs": [],
      "source": [
        "num_ftrs = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(num_ftrs, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL4RBHN4gxUl"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPoerMD7gy71"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98SwTUzvg0bd"
      },
      "outputs": [],
      "source": [
        "exp_lr_scheduler = StepLR(optimizer,\n",
        "step_size=7,\n",
        "gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-XsZl-1g1pV",
        "outputId": "9bb2ad13-5807-45fe-f441-ceb75c13d407"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [0/1]: 100%|██████████| 40/40 [05:13<00:00,  7.83s/it, acc=tensor(0.8400), loss=0.0486]\n"
          ]
        }
      ],
      "source": [
        "num_epochs=1\n",
        "for epoch in range(num_epochs):\n",
        "    loop = tqdm(enumerate(train_loader), total=len(train_loader))\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    for batch_idx, (inputs, labels) in loop:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs,1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()/inputs.size(0)\n",
        "        running_corrects += \\\n",
        "            torch.sum(preds == labels.data) \\\n",
        "                /inputs.size(0)\n",
        "        exp_lr_scheduler.step()\n",
        "        train_epoch_loss = \\\n",
        "            running_loss / len(train_loader)\n",
        "        train_epoch_acc = \\\n",
        "            running_corrects / len(train_loader)\n",
        "            \n",
        "        loop.set_description(f'Epoch [{epoch}/{num_epochs}]')\n",
        "        loop.set_postfix(loss = train_epoch_loss, acc = train_epoch_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0iyaX-wg4hk",
        "outputId": "f81f8fe4-3f35-475d-9a37-6cd18e747840"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [0/1]: 100%|██████████| 40/40 [05:11<00:00,  7.79s/it, acc=tensor(0.8525), loss=0.0492]\n"
          ]
        }
      ],
      "source": [
        "num_epochs=1\n",
        "for epoch in range(num_epochs):\n",
        "    loop = tqdm(enumerate(train_loader), total=len(train_loader))\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    for batch_idx, (inputs, labels) in loop:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs,1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()/inputs.size(0)\n",
        "        running_corrects += \\\n",
        "            torch.sum(preds == labels.data) \\\n",
        "                /inputs.size(0)\n",
        "        exp_lr_scheduler.step()\n",
        "        train_epoch_loss = \\\n",
        "            running_loss / len(train_loader)\n",
        "        train_epoch_acc = \\\n",
        "            running_corrects / len(train_loader)\n",
        "            \n",
        "        loop.set_description(f'Epoch [{epoch}/{num_epochs}]')\n",
        "        loop.set_postfix(loss = train_epoch_loss, acc = train_epoch_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US4EYQ__lrdT",
        "outputId": "1d189386-c37f-4e4c-89b4-a5580c114bce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [0/1]: 100%|██████████| 120/120 [16:25<00:00,  8.21s/it, acc=tensor(0.6250), loss=0.109]\n"
          ]
        }
      ],
      "source": [
        "num_epochs=1\n",
        "for epoch in range(num_epochs):\n",
        "    loop = tqdm(enumerate(train_loader), total=len(train_loader))\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    for batch_idx, (inputs, labels) in loop:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs,1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()/inputs.size(0)\n",
        "        running_corrects += \\\n",
        "            torch.sum(preds == labels.data) \\\n",
        "                /inputs.size(0)\n",
        "        exp_lr_scheduler.step()\n",
        "        train_epoch_loss = \\\n",
        "            running_loss / len(train_loader)\n",
        "        train_epoch_acc = \\\n",
        "            running_corrects / len(train_loader)\n",
        "            \n",
        "        loop.set_description(f'Epoch [{epoch}/{num_epochs}]')\n",
        "        loop.set_postfix(loss = train_epoch_loss, acc = train_epoch_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRKFEOi7CySO",
        "outputId": "a0f194eb-942e-40ce-cd6b-7c11f4333fe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: Loss: 0.0486 Acc: 0.8400 Val: Loss: 0.0480 Acc: 0.8300\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "running_loss = 0.0\n",
        "running_corrects = 0\n",
        "\n",
        "for inputs, labels in val_loader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    _, preds = torch.max(outputs,1)\n",
        "    loss = criterion(outputs, labels)\n",
        "    running_loss += loss.item()/inputs.size(0)\n",
        "    running_corrects += \\\n",
        "        torch.sum(preds == labels.data) \\\n",
        "            /inputs.size(0)\n",
        "epoch_loss = running_loss / len(val_loader)\n",
        "epoch_acc = \\\n",
        "    running_corrects.double() / len(val_loader)\n",
        "print(\"Train: Loss: {:.4f} Acc: {:.4f}\"\n",
        "    \" Val: Loss: {:.4f}\"\n",
        "    \" Acc: {:.4f}\".format(train_epoch_loss,\n",
        "                        train_epoch_acc,\n",
        "                        epoch_loss,\n",
        "                        epoch_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-vdDEV4hk-s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEEnxR57Rbrw"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_FXUs52Rbjs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "ProjectDMPyTroch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
